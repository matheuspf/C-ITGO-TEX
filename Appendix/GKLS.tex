% !TEX root = ../ITGO.tex

\section*{GKLS class of functions}

We used C-ITGO to optimize the 800 functions generated by the GKLS generator \citep{GKLS}, considering the differentiable type (“D”). There are 100 functions for each setup, namely, with 2, 3, 4 and 5 variables, each consisting of an “easy” and “hard” case. The parameters used for each class of functions follows:


\input{Appendix/Tables/GKLS_Params}


\noindent
Where:


\begin{itemize}

\item $N$ - problem dimension;
\item $M$ - number of local optima;
\item $\Delta$ - accuracy coefficient;
\item $\rho^*$ - radius of the attraction region of the global optimum;
\item $r^*$ - distance from the global optimum to the vertex of the paraboloid.

\end{itemize}


We compared the results achieved by C-ITGO against a number of deterministic global optimization methods. We used the approach described in \cite{NAT} to compare meta-heuristics with deterministic algorithms. For each of the 100 problems of a given class, we ran C-ITGO 100 times, saving the mean number of function/gradient evaluations for that problem. We stopped when the best solution $\bm{x}'$ found in a run satisfies:\\[-2.5em]

\begin{equation}\label{eq:Convergence}
    |x'(i) - x^*(i)| \leq \sqrt{\Delta}(b(i) - a(i)), \qquad 1 \leq i \leq N,
\end{equation}


\noindent
where $\bm{x}^*$ is the global optimal solution and $\bm{a}$ and $\bm{b}$ are respectively the lower and upper bound vectors defining the problem's domain.

The deterministic methods used for comparison are DIRECT \citep{DIRECT}, DIRECT-L \citep{DIRECTL}, ADC \citep{ADC}, SGEO-QN \citep{SGEO} (using $P_4$) and DIRECT-KS \citep{ADC2}. 

The parameters used in C-ITGO are presented in Table \ref{tab:ITGO}. Because the GKLS classes of problems are unconstrained, the $\alpha$ parameter is omitted and the stochastic topographical heuristic is not used. The L-BFGS algorithm was used as the local search for unconstrained smooth optimization. A very small number of local search calls were necessary to reach convergence.

\input{Appendix/Tables/ITGO}

Table \ref{tab:Results} shows the results comparing the mean number of function/gradient evaluations necessary to achieve condition \ref{eq:Convergence}. We use the same notation as in \cite{NAT}, where “$>$m(i)” states that \textit{i} problems were not solved under $10^6$ function evaluations.


\input{Appendix/Tables/GKLS_Results}

We see from the results presented in Table \ref{tab:Results} that C-ITGO has promising results, having a smaller mean number of function/gradient evaluations than most methods in most cases. It seems that the radius of the attraction region is the parameter which impacts most on the C-ITGO performance.

However, the DIRECT-KS presents the best statistics in all cases. We decided to execute a nonparametric statistical test, the Wilcoxon test \citep{Friedman}, to check if there is any significant difference between the C-ITGO and the DIRECT-KS method.

Table \ref{tab:Wilcoxon2} shows the results generated using the R package \textit{wilcoxon.test}, considering DIRECT-KS against the other methods. 

We would like to explore further the effectiveness of C-ITGO for the unconstrained case in a future work, possibly improving the current results.


\include{Appendix/Tables/Wilcoxon2}