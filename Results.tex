\section{Computational Results} \label{sec:Results}

The C-ITGO was implemented using Matlab, and the experiments were accomplished on a machine with the Intel i3-3110M CPU @2.40GHz processor with 4GB of RAM, running Windows 7. Also, we provide a free library for using C-ITGO for optimizing any user-defined function, being it constrained or not. The library uses by default the Matlab \textit{fmincon} solver for continuous problems and the OPTI toolbox (currently only readily available for Windows, but can be compiled for Linux and Mac as well) for mixed integer problems. Also, the user has the option to easily incorporate other local search algorithms, if desired.

%The source code for the reported results in this work can be found and downloaded for free at \cite{GIT}.

To evaluate the performance of the developed method to solve real-world problems, we use eight difficult constrained engineering optimization problems from the literature, whose objective functions and constraints are diverse (quadratic, cubic, polynomial and nonlinear) with many numbers and types of design variables (continuous, mixed and integer). 

In all tests, given the stochastic characteristic of C-ITGO, we run it 25 times, saving the Best and Worst feasible solutions, as well as the mean value (Mean) and standard deviation (SD) of the fitness after all runs. Given the great variability between the results found in the literature for most problems, we stop the execution of C-ITGO as soon as the best solution found in a run is considerably close to the optimum (the optimum solution for each of the eight engineering design problems considered is known). That is, the condition for stopping C-ITGO, when the fitness reaches a certain value, is problem dependent. At the end, the mean number of function evaluations (MNFEs) is reported for all runs.

Table \ref{tab:GAP} shows the values that determine the convergence of C-ITGO for each problem. The values in row \textit{GAP} represent the minimum Euclidean distance to the optimum that the fitness of a solution needs to be in order to stop the execution of C-ITGO. These values were chosen based on the results found by the competing methods, considering the variability of the precision of the reported solutions.

\input{Tables/GAP}

The Gear Train (GT) was the only problem where we specified a maximum number of function evaluations. For this problem, if the NFEs reaches 800, we stop immediately and return the best solution found. It was necessary since the convergence requirements for this problem is very tight ($10E-10$). All other problems converged to at least \textit{GAP} of the optimum without the requirement to specify a maximum NFEs.

%The C-ITGO method finishes its execution when one or both of the two stop criteria is achieved: the convergence of the best individual or the maximum number of function calls is reached. Table \ref{tab:GAP} shows the values that determine the convergence of C-ITGO for each problem. The values in row GAP represent the minimum euclidean distance to the optimum that the fitness of a solution needs to be in order to stop the execution of C-ITGO. These values are chosen based on the results reported by the competing methods, considering the variability of the precision of the solutions among the problems.



In our tests, all solutions reported by C-ITGO are completely feasible for all problems. So, unless specified, we exclude from comparison methods that violate any constraint (unfeasible).

We compare 20 different optimization methods against C-ITGO. The most common meta-heuristic for solving the problems considered in this work is the Particle Swarm Optimization (PSO), including PSO-DE \citep{PSO-DE}, a hybrid PSO method combined with Differential Evolution (DE); the HPSO \citep{HPSO}, another hybridized particle swarm method in combination with simulated annealing; a co-evolutionary PSO denominated CPSO \citep{CPSO}; the hybridized PSO with Nelder-Mead simplex (NM-PSO) \citep{NM-PSO}; the Unified PSO (UPSO) \citep{UPSO}, a PSO variant that balances exploration and exploitation; the APSO, standing for Accelerated PSO  \citep{APSO}; the Gaussian Quantum-Behaved Particle Swarm Optimization methods, named QPSO and G-QPSO \citep{QPSO}; and the IPSO \citep{IPSO}, which incorporates an interval reducing procedure. More recently, and among the best PSO methods for constrained global optimization, we can cite the Improved Accelerated PSO algorithm (IAPSO) \citep{IAPSO}, which proposes some modifications and improves the APSO method.

Many other different optimization methods were also used for comparison in this work: the Mine Blast Algorithm (MBA) \citep{MBA}, a population-based optimization method based on the mine bomb explosion concept; the League Championship Algorithm (LCA) \citep{LCA}, which models a league championship environment with artificial teams; the Crossover-Based Artificial Bee Colony (CB-ABC) \citep{CB-ABC}, applying modified search operators over the regular ABC algorithm; the Differential Evolution with Level Comparison (DELC) \citep{DELC}, which converts a constrained problem into an unconstrained one by means of a level comparison mechanism; a Multi-View Differential Evolution (MVDE) \citep{MVDE}, which uses several different mutation strategies at every iteration; the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) method \citep{CMA-ES}, which builds a distribution model of the population; the Water Cycle Algorithm (WCA) \citep{WCA}, a nature-inspired method based on the water cycle process; and the Cuckoo Search algorithm (CS) \citep{CS}, another nature-inspired method based on the cuckoo bird species behavior. Recently, reporting state-of-the-art results for some problems, we can cite the Improved Artificial Bee Colony with Modified Augmented Lagrangian (IABC-MAL) \citep{IABC-Mal}, which integrates the Modified Augmented Lagrangian method to handle constraints with the Improved ABC algorithm \citep{IABC}, and the Self-Adaptive Multi-Population based Jaya (SAMP-Jaya) algorithm \citep{SAMP-Jaya}, a multi-population scheme of the Jaya method \citep{Jaya}.


Following, the engineering optimization problems that will be tackled in this work will be briefly explained, as well as the solutions obtained by C-ITGO against the solutions of the best previously cited competing techniques of the literature. Further information on the Welded Beam (WB), Tension/Compression Spring (TC), Speed Reducer (SRI and SRII), Pressure Vessel (PV), Gear Train (GT) and Multiple Disk clutch brake (MD) problems can be found in the work of \cite{IAPSO}. The Three-Bar truss (TB) problem and additional information on Welded Beam (WB), Tension/Compression Spring (TC), Speed Reducer (SRI), Pressure Vessel (PV) and Gear Train (GT) can be seen in the work of \cite{MBA}.


We also decided to add in the appendix the initial results of applying the developed method to the GKLS class of problems \citep{GKLS}. We plan to improve C-ITGO further in a future work to better tackle unconstrained smooth optimization problems, comparing the results against a number of efficient deterministic global optimization methods.


\subsection{Welded beam design problem}


\input{Appendix/WB}


We compare the results obtained by C-ITGO against a number of state-of-the-art methods used to solve this problem, including PSO-DE, HPSO, UPSO, MBA, CMA-ES, MVDE, CPSO, LCA, IPSO, CB-ABC, DELC, IABC-MAL, NM-PSO, APSO, WCA, IAPSO and SAMP-Jaya. Table \ref{tab:WB} shows the comparison of the statistical results obtained by all cited methods to solve the welded beam design problem. All the methods, with exception of CMA-ES, SAMP-Jaya and C-ITGO, took more than 10,000 iterations to achieve good quality solutions. C-ITGO achieved optimal solutions with a very small standard deviation of 3.65E-12, using ten times fewer function evaluations on average than most of the methods.

We write the statistics for the C-ITGO method in bold simply to highlight the reported results, not because it always presents the best statistics for all problems.

\input{Tables/WB}

The results for C-ITGO and SAMP-Jaya are very similar, with the former having a slightly worse standard deviation, but converging in less than one-third of the number of function evaluations. We note here that the best solution achieved by NM-PSO is slightly unfeasible, so it should not be directly compared to the other methods.




\subsection{Tension/compression spring design problem}


\input{Appendix/TC}


A variety of methods were used in literature to solve the tension/compression spring design problem. Between them, we can cite CPSO, HPSO, NM-PSO, MBA, UPSO, PSO-DE, LCA, CB-ABC, QPSO, G-QPSO, APSO, CMA-ES, MVDE, DELC, WCA, IPSO, IAPSO, IABC-MAL and SAMP-Jaya. Table \ref{tab:TC} shows the statistical results of all methods, along with the number of function evaluations taken to achieve such results.

\input{Tables/TC}


The methods vary greatly in the number of function evaluations required to converge to good quality solutions. Only three of the methods (QPSO, G-QPSO and IAPSO) achieved convergence with 2,000 function evaluations, while some methods required more than 100,000. The best solution achieved by all methods have the same fitness value up to five decimal places, with the exception of CPSO, UPSO, APSO and NM-PSO.
 
The best solution reported by NM-PSO is again unfeasible, so we do not compare it against other methods. The SAMP-Jaya method also seems to report a slightly unfeasible best solution, differing from the optimal value reported by other methods. However, the result achieved by SAMP-Jaya differs only at the sixth decimal place, and the difference may be due to wrong rounding. We cannot state this for sure since we do not have access to the solution vector found by the method. Given the differences between the precision in the solutions reported by the methods, we consider $f(\bm{x}) = 0.012665$ to be the fitness at the global optimum.

The C-ITGO method performed remarkably well on this problem, converging to the best solution found in 535.08 function evaluations on average, almost four times less than the second best competing method. Also, the standard deviation is very small, in the order of 2.81E-9. 

Given the relatively small domain of the problem, we believe that the C-ITGO method was able to cover the space efficiently, providing hot starting points for the local search method, which proved to be very effective in this case.




\subsection{Three-bar truss design problem}

\input{Appendix/TB}


Here we present only the five best-performing methods used to solve this problem since the solutions found in the literature have very small variance from each other. These methods are PSO-DE, CMA-ES, MVDE, DELC, MBA and IABC-MAL. We present the statistical results for this problem in Table \ref{tab:TB}.

\input{Tables/TB}

From Table \ref{tab:TB} it is possible to note that all methods have very similar results, differing mainly in the number of function calls. This is not surprising, given that the problem is simpler, has fewer variables and consequently has a smaller domain than any other engineering design problem considered in this work.

C-ITGO achieved convergence quickly, taking 136.48 function evaluations on average. In this problem, we have set a small population, as well as a small number of function calls allowed in the local search procedure. Thus, we obtained the lowest MNFEs than any of the competing techniques, at least ten times lower. It seems that the solutions found by the topographical heuristic were already close to the optimum, so the local search converged in very few iterations. However, the C-ITGO method has a slightly worse standard deviation than DELC and IABC-MAL.



\subsection{Speed reducer design problem}

\input{Appendix/SR}


For SRI, we compare C-ITGO results against four optimization methods, namely LCA, IPSO, APSO and IAPSO, shown in Table \ref{tab:SP1}.

The LCA, IPSO, IAPSO and C-ITGO present similar results, all finding the constrained global optimum solution and having very low standard deviation.


\input{Tables/SP1}

The first three methods take at least 20,000 iterations to converge to good quality solutions, while IAPSO takes only 6,000 NFEs. C-ITGO outperforms the other methods by a large margin, converging in 858.40 function calls on average while maintaining negligible higher standard deviation than IAPSO and IPSO.

For this problem, we used considerably greater populations, of sizes 150 ($PS_1$) and 10 ($PS_2$), while maintaining the number of allowed function evaluations of the local search relatively small (100 and 200). For the worst case, C-ITGO took 3 full iterations to converge, while in most cases it converged in the first iteration.

For SRII, the methods used for comparison were PSO-DE, WCA, DELC, CB-ABC, CMA-ES, MVDE, IABC-MAL, LCA, APSO, MBA, IPSO, IAPSO and SAMP-Jaya. The reported results for the SAMP-Jaya method seems to violate the integer constraint at variable three, but it is included to show that even in harder situations the C-ITGO algorithm can still produce state-of-the-art results.

From Table \ref{tab:SP2}, we can see that DELC, CMA-ES, MVDE, IABC-MAL, LCA, IAPSO, SAMP-Jaya and C-ITGO are the only methods that converged to the optimum in every run, having very small standard deviation. Although similar results are observed regarding the quality of the solutions, C-ITGO converges much faster than any competing method, using seven times fewer function evaluations than SAMP-Jaya. The standard deviation achieved by C-ITGO is also only worse than the standard deviation reported by IABC-MAL (the difference is in the order of 1E-13), which took 15,000 function evaluations to converge.

\input{Tables/SP2}

For this specific problem, we used the SQP algorithm as local search and rounded the value of the third variable. In this case, this approach proved to converge much faster than using a mixed integer local search. Also, the first population size is considerably smaller than the one used in SRI (100 in this problem).



\subsection{Pressure vessel design problem}

\input{Appendix/PV}


We compare C-ITGO against the UPSO, QPSO, G-QPSO, CMA-ES, MVDE, CB-ABC, PSO-DE, HPSO, WCA, LCA, APSO, CPSO, MBA, IPSO, DELC, IABC-MAL, SAMP-Jaya and IAPSO methods. The statistical results are shown in Table \ref{tab:PV}. Some of the methods used to solve this problem report unfeasible results (PSO-DE, WCA, MBA and SAMP-Jaya), probably either because the integer constraints are ignored or due to wrong rounding. Nevertheless, we still use the results of these methods to prove the superior convergence of C-ITGO, even in constrained mixed integer problems.


\input{Tables/PV}


The algorithms CMA-ES, CB-ABC, HPSO, IABC-MAl, IPSO, DELC, IAPSO and C-ITGO are the only who found the feasible optimal solution. All other methods presented relatively poor performance, with much higher NFEs on average. C-ITGO takes less than five times the number of function evaluations to converge than the best competing method, SAMP-Jaya, which reported a result of 6513.33 MNFEs. Also, C-ITGO achieves the smallest standard deviation among all methods. All runs of C-ITGO converged quickly to the known global optimum, showing unarguably better results than any other method compared in this problem.



\subsection{Gear train design problem}

\input{Appendix/GT}


We compare the C-ITGO results, shown in Table \ref{fig:GT}, against other five methods: MBA, UPSO, CS, APSO and IAPSO. In general, all methods compared achieved similar results, having found the global optimal solution for the problem. The main difference relies on the number of function calls, varying from 100,000 for UPSO to 800 for IAPSO.

\input{Tables/GT}


Since this is an integer optimization problem, we used the mixed integer local search based on the NOMAD solver. In this problem, the solver had some difficulty in some runs, achieving 6.85E-09 of standard deviation, more than IAPSO, CS and MBA. The mean fitness value, however, is just worse than the CS method, which takes 5,000 function calls to converge. Besides this drawbacks, C-ITGO was the fastest method to achieve convergence, taking only 773.0 function calls on average.



\subsection{Multiple disk clutch brake design problem}

\input{Appendix/MD}


To compare the results, we used only methods who achieved close performance to the obtained by C-ITGO, since some methods in literature have very diverging results. The methods compared are WCA, IPSO, APSO and IAPSO. The WCA, IPSO, and IAPSO methods achieved good performance in this problem, finding the global optimal solution and having very small variance, as shown in Table \ref{tab:MD}. The WCA and IAPSO took very few function evaluations to converge, respectively 500 and 400. IPSO took long more, with 20,000 function evaluations. However, the reported standard deviation for IPSO was 0.0.

\input{Tables/MD}

The C-ITGO clearly outperforms the other methods, having a standard deviation of 1.13E-16, while converging with only 286.48 function evaluations on average. For this problem, we used very small populations, of sizes 20 ($PS_1$) and 5 ($PS_2$). The number of function evaluations in the first step was 100, and most runs converged in much less, enjoying the quality of initial solutions provided by the topographical heuristic step. Some runs, however, took more than 1,000 function evaluations, bringing the mean NFEs up.



\subsection{Best Solutions to the Engineering Problems}

Table \ref{tab:BestResults} shows the fitness value, the values of the variables and the values of the constraints for the best solution found by C-ITGO for all problems. The precision of the results of each problem was set to match the results reported by the competing methods cited in this work. However, to the best of our knowledge, the best solution found by C-ITGO for each problem is equal to, or negligibly worse (up to several decimal places) than the best solutions reported by state-of-the-art methods.

\input{Tables/BestResults}


\subsection{Statistical Tests To Analyse the Computational Results}

We now prove the significant improvement of C-ITGO over the competing methods by means of a nonparametric statistical test, where no assumptions are made regarding the underlying distribution of the data. Since no other algorithm than C-ITGO solves all the eight engineering design problems presented in this paper, we cannot apply typical statistical methods, such as the Friedman test \citep{Friedman}.

Instead, we use the Skillings-Mack test \citep{Skillings}, which is a Friedman\allowbreak-type statistical test that can be used when there are missing data, and that reduces to the Friedman test when the data has no missing entries. Just as in the Friedman test, the Skillings-Mack test finds the rank of the competing algorithms for each problem and then calculates the mean or average rank. The lower the mean rank, the better is the performance of the algorithm. The Skillings-Mack statistical test is also useful when there are many ties or equal ranks, as well as for small samples.

The method reports a \textit{p-value}, the probability that, when the null hypothesis is assumed to be true (in this case, no difference between the performance of the optimization methods), the results observed by the experiments at hand are at least of the same magnitude that the true values that would be observed in the limit of an infinite number of samples. Thus, a small p-value, say less than 0.05, represents a high chance that the null hypothesis is false.

In this work, the mean number of function evaluations (MNFEs) is used as the comparing metric. We used the \textit{Skillings.Mack} package \citep{SkillMack} of the \textit{R} language \citep{R} to report the following results.

In Table \ref{tab:SkillMack_3} we show the results of applying the statistical test to all the methods that solved at least three of the eight engineering design problems considered in this work. The mean rank of C-ITGO is 1.0, given that it has the smallest MNFEs for all problems. That is much less than IAPSO and SAMP-Jaya, which have a mean rank of 2.75. The mean ranks are also shown in the form of a bar plot for all methods in Figure \ref{fig:SkillMack_3}.


\input{Tables/SkillMack_3}


As shown in Table \ref{tab:SkillMack_3}, the value of the Skillings-Mack statistic is 63.66813949 with an approximate p-value of 1.2469E-07 calculated from the chi-squared distribution with 16 degrees of freedom, which strongly implies that the null hypothesis does not hold true at the critical level of $\alpha$ = 0.05 or $\alpha$ = 0.01. That is, there is at least one method that is significantly better than the others. 



\begin{figure}[h]
    \begin{center}
    \includegraphics[scale=0.6]{Imgs/SkillMack_3-crop.pdf}
    \end{center}
    \captionsetup{justification=centering}
    \vspace*{-4mm}
    \caption{Mean rank plot for all methods that solve at least three problems.}\label{fig:SkillMack_3}
\end{figure}



We also show in Table \ref{tab:SkillMack_5} the results of applying the Skillings-Mack test to the methods that solved at least five problems. For this case, the value of the Skillings-Mack statistic is 44.23462786 with an approximate p-value of 7E-06 calculated from the chi-squared distribution with 11 degrees of freedom. The difference between the results reported in Table \ref{tab:SkillMack_3} is mainly due to the reduction of the number of methods, and the exclusion of some methods that performed well, but in four or fewer problems, such as SAMP-Jaya.

\input{Tables/SkillMack_5}

\begin{figure}[bp]
    \begin{center}
    \includegraphics[scale=0.6]{Imgs/SkillMack_5-crop.pdf}
    \end{center}
    \captionsetup{justification=centering}
    \vspace*{-4mm}
    \caption{Mean rank plot for all methods that solve at least five problems.}\label{fig:SkillMack_5}
\end{figure}

We see again that C-ITGO has a mean rank of 1.0, far less than IAPSO with 2.375, standing in second place. The plot for the mean rank is shown in Figure \ref{fig:SkillMack_5}. The p-value (7E-06) for this case is also very small, rejecting the null hypothesis at critical level of $\alpha$ = 0.05 or $\alpha$ = 0.01.


We also present in Table \ref{tab:SignedTest} the results of applying the pairwise signed test, comparing C-ITGO against the same methods presented in Table \ref{tab:SkillMack_5} and considering the same performance metric. Here, a "+" represents that C-ITGO outperforms the corresponding method, a "=" represents a tie, and a "-" represents a loss (C-ITGO has worse performance than the corresponding method). If a method does not solve a certain problem, that entry is ignored (marked with "*"). The last row shows the final sum of the number of "+", "=" and "-" for all methods.

\input{Tables/SignedTest}

As we can see from Table \ref{tab:SignedTest}, C-ITGO always has a better MNFEs than any method for all problems, so there are only "+" entries. Following the guidelines presented in \cite{Friedman}, we can conclude that C-ITGO always achieves a p-value of at least 0.05 when compared to the methods of Table \ref{tab:SignedTest}.


To prove the superior convergence of C-ITGO, we present one more nonparametric statistical test, the Wilcoxon signed rank test, also described in \cite{Friedman}. This is a more robust approach to a pairwise statistical comparison than the previous test, that aims to detect a significant difference between the means of two competing techniques. 

The results shown in Table \ref{tab:Wilcoxon} were generated using the R package \textit{wilcoxon.test}, considering C-ITGO against the other algorithms. Empty entries (problems not solved by some method) are treated by default.
%Methods that solve fewer problems have a higher uncertainty regarding its distribution, consequently having a higher p-value.

\input{Tables/Wilcoxon}


Given that C-ITGO always had the best MNFEs when compared to all the other methods, as the Table 15 states, C-ITGO shows a improvement over IABC-MAL, MBA, LCA, CMA-ES, MVDE and APSO  with a level of significance $\alpha$ = 0.01, and over IAPSO with a level of significance $\alpha$ = 0.02.