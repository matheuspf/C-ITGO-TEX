% !TEX root = ../ITGO.tex

\section*{GKLS class of functions}

We used C-ITGO to optimize the 800 functions generated by the GKLS generator \citep{GKLS}, considering the differentiable type (“D”). There are 100 functions for each setup, namely, with 2, 3, 4 and 5 variables, each consisting of “easy” and “hard” cases. The parameters used for each class of functions follows:


\input{src/Appendix/Tables/GKLS_Params}


\noindent
Where:


\begin{itemize}

\item $N$ - problem dimension;
\item $M$ - number of local optima;
\item $\Delta$ - accuracy coefficient;
\item $\rho^*$ - radius of the attraction region of the global optimum;
\item $r^*$ - distance from the global optimum to the vertex of the paraboloid.

\end{itemize}


We compared the results achieved by C-ITGO against a number of deterministic global optimization methods. We used the approach described in \cite{NAT} to compare meta-heuristics with deterministic algorithms. For each of the 100 problems of a given class, we ran C-ITGO 100 times, saving the mean number of function/gradient evaluations for that problem. We stopped when the best solution $\bm{x}'$ found in a run satisfies:\\[-2.5em]

\begin{equation}\label{eq:Convergence}
    |x'(i) - x^*(i)| \leq \sqrt{\Delta}(b(i) - a(i)), \qquad 1 \leq i \leq N,
\end{equation}


\noindent
where $\bm{x}^*$ is the global optimal solution and $\bm{a}$ and $\bm{b}$ are respectively the lower and upper bound vectors defining the problem's domain. For all the GKLS problems, the fitness at the global optimum is $f(\bm{x}^*) = -1.0$ and the bounds are $a(i) = -1.0, \ i = 1, ..., N$, and $b(i) = 1.0, \ i = 1, ..., N$.

The deterministic methods used for comparison are DIRECT \citep{DIRECT}, DIRECT-L \citep{DIRECTL}, ADC \citep{ADC}, SGEO-QN \citep{SGEO}, and the algorithm described in \cite{ADC2}, which we call DIRECT-KS. We also compared C-ITGO agains the meta-heuristics used in \cite{NAT}, namely, a Genetic Algorithm (\textbf{GA}), Artificial Bee Colony (\textbf{ABC}) and Firefly Algorithm (\textbf{FA}). It is important to consider that the deterministic global optimization methods considered for numerical comparisons do not perform local searches, as the proposed method does; the introduction of a local search procedure inside the schemes of these methods would furthermore accelerate their execution.

The parameters used in C-ITGO are presented in Table \ref{tab:ITGO}. Because the GKLS classes of problems are unconstrained, the $\alpha$ parameter is omitted and the stochastic topographical heuristic is not used. The L-BFGS algorithm was used as the local search for unconstrained smooth optimization. A very small number of local search calls were necessary to reach convergence.

\input{src/Appendix/Tables/ITGO}

Table \ref{tab:Results} shows the results comparing the mean number of function/gradient evaluations necessary to achieve condition stated by equation \ref{eq:Convergence}. We use the same notation as in \cite{NAT}, where “$>$m(i)” states that \textit{i} problems were not solved under $10^6$ function evaluations.\\


\input{src/Appendix/Tables/GKLS_Results}

We see from the results presented in Table \ref{tab:Results} that C-ITGO has promising results, having a smaller mean number of function/gradient evaluations than most methods in most cases. It seems that the radius of the attraction region is the parameter which impacts most on the C-ITGO performance. 

Table \ref{tab:GKLS_Stats} shows some more statistics regarding the number of function evaluations executed by C-ITGO. The set of columns under `Statistics for all the 10,000 runs' presents the minimum (\textbf{Min}), maximum (\textbf{Max}) and standard deviation (\textbf{STD}) of the NFEs calculated from the 10,000 runs for each of the eight classes of problems. The set of columns under `Statistics after averaging the 100 runs for each problem' shows the minimum (\textbf{Min}), maximum (\textbf{Max}) and standard deviation (\textbf{STD}) after averaging the NFEs required to solve all 100 problems of each class. As is possible to see in the Table \ref{tab:GKLS_Stats}, the worst run of the C-ITGO method required far less than $10^6$ and $10^5$ NFEs to reach convergence for any problem of the hard and easy classes respectively.

\input{src/Appendix/Tables/GKLS_Stat}

Figures \ref{fig:OpZone_a} and \ref{fig:OpZone_b} show the \textit{Operational Zones} for the C-ITGO algorithm, considering the easy and hard cases of the 5-dimensional class respectively. The 10,000 runs of the C-ITGO algorithm were used to generate the curves, as described in \cite{NAT}. Figures \ref{fig:OpCarac_a} and \ref{fig:OpCarac_b} show the comparison of the operational zones with the operational characteristics of some of the deterministic methods considered.



\begin{figure}[h]
    \centering
    \begin{subfigure}{.5\textwidth}
      \centering
      \includegraphics[width=1.1\linewidth]{img/GKLS/mult_5E}
      \caption{}
      \label{fig:OpZone_a}
    \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
      \centering
      \includegraphics[width=1.1\linewidth]{img/GKLS/mult_5H}
      \caption{}
      \label{fig:OpZone_b}
    \end{subfigure}
    \caption{The operational zones built using the 10,000 runs performed by the C-ITGO algorithm for the five dimensional easy (a) and hard (b) cases. The lower and upper bounds are in blue, while the mean is in red.}\label{fig:OpZone}
\end{figure}


\begin{figure}[h]
    \centering
    \begin{subfigure}{.5\textwidth}
      \centering
      \includegraphics[width=1.1\linewidth]{img/GKLS/fill_5E_edit}
      \caption{}
      \label{fig:OpCarac_a}
    \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
      \centering
      \includegraphics[width=1.1\linewidth]{img/GKLS/fill_5H_edit}
      \caption{}
      \label{fig:OpCarac_b}
    \end{subfigure}
    \caption{Operational zones built on the two 5-dimensional classes for the C-ITGO algorithm, and operational characteristics of the DIRECT, DIRECT-L and ADC methods.}\label{fig:OpCarac}
\end{figure}


However, the DIRECT-KS presents the best statistics in all the cases considered. Thus, we decided to execute a nonparametric statistical test, the Wilcoxon test \citep{Friedman} (which is very useful to compare the performance of two algorithms when applied to a common set of problems), to check if there is any statistically significant difference of performance between C-ITGO and the DIRECT-KS method.

Table \ref{tab:Wilcoxon2} shows the results generated using the \textit{wilcoxon.test} command of the R software, considering DIRECT-KS as reference/control against the other methods. 

\input{src/Appendix/Tables/Wilcoxon2}

The ADC method shows an improvement over DIRECT and SGEO-QN with a level of significance of $\alpha$ = 0.05, and over DIRECT-L with a level of significance of $\alpha$ = 0.1. When compared to ADC and C-ITGO, the probability of presenting any significant statistical difference is bellow 80\%, what is indicated by a p-value greater than 0.2. 

When considering the eight different cases of the GKLS function generator, we can conclude that there is not any significant statistical difference between the C-ITGO and the ADC methods, showing that the performance of C-ITGO is equivalent to the DIRECT-KS over the GKLS generated problems considered in this work.

We would like to explore further the effectiveness of C-ITGO for the unconstrained case in a future work, possibly improving the current results.