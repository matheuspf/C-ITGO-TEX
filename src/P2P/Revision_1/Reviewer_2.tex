% !TEX root = ../main.tex

\section*{Reviewer \#2}

{\color{red} However, as presented, the experimental part is far from being considered for publication in such a prestigious peer-reviewed journal as ``Expert Systems with Applications". }\\

The authors would like to mention that recent papers published in ``Expert Systems with Applications" present results in a very similar (if not completely equal) fashion. See for example some methods used for comparison with C-ITGO: \cite{NM-PSO}, \cite{CMA-ES}, \cite{MVDE}, \cite{QPSO}. These papers do not present however any statistical analysis, such as extensively done in the C-ITGO paper.


\vspace{1cm}


{\color{red} Parameters of the considered C-ITGO method are tuned for particular applied problems and it is not clear how these parameters should be specified to solve a concrete class of global optimisation problems.} \\

The eight engineering problems considered present very different characteristics, such as different number of variables, constraints, continuity, smoothness, size of the domain, number of local optima and value of the objective function at the optimal. It is simply infeasible to use a single set of parameters in such a diverse collection of problems, considering the effectiveness of the competing methods.

Tuning parameters of a meta-heuristic for a given problem is a common practice in literature, and most methods considered for comparison use specific parameters for each problem (see for example \cite{IPSO}, \cite{IAPSO} and \cite{IABC-Mal}). Some authors even use a grid search approach to exhaustively look for better parameters. It was not necessary in our case since C-ITGO is not too sensitive to the choice of most parameters.

The impact of each parameter of C-ITGO in the overall performance of the method should be clear from the thorough discussion about the algorithm, using pseudocodes, examples and images. However, as it yet not clear for the reviewer \#2, we decided to include some paragraphs dedicated to describe guidelines on how to choose those parameters.


\vspace{1cm}


{\color{red} Parameters of the metaheuristic methods taken for the comparison are not indicated.} \\

As we compare 19 methods in the paper, it is not feasible to include the set of parameters used for each problem for each method. As we used results available from the literature, it is trivial for the reviewer \#2 to check the parameters used in the competing methods as we cite every work in the C-ITGO paper.


\vspace{1cm}


{\color{red} The choice of the methods themselves and problems to benchmark the algorithms are not justified to present valid conclusions on the methods' performance. Test classes (see Gaviano et al. (2003)) should be used for this aim and a thorough comparison with efficient deterministic global optimization techniques (see Mockus et al. (2017), Fok et al. (2017)) is necessary to ascertain a real position of the metaheuristics in solving the considered applied problems...} \\

The GKLS \cite{GKLS} is a collection of unconstrained optimization functions, which is fundamentally different from the goal of C-ITGO (namely, constrained optimization). However, we included in the appendix of the paper the results of applying C-ITGO to the 800 problems generated by GKLS (easy and hard cases, for 2, 3, 4 and 5 variables). The results were compared against some efficient deterministic global optimization methods, such as the techniques cited by the reviewer \#2. A nonparametric statistic (Wilcoxon) test was performed to compare the methods.

In this paper, we postpone deeper results over GKLS test for a future work, given that this would effectively change the focus of the paper and considerably increase the text length. Also, we will have the opportunity to make changes in the current algorithm to better tackle this type of optimization problems.

\vspace{1cm}



{\color{red} ...(please take into account that the number of function evaluations is to be multiplied by the number of runs of a metaheuristic method - 25 in this paper). } \\

The authors are unfamiliar with this type of comparison. Instead, we follow the guidelines described in \cite{NAT} to compare deterministic and meta-heuristic methods, which seems far more reasonable. 

To compare C-ITGO with the meta-heuristics, we used the Mean Number of Function Evaluations (MNFEs) as the performance metric and not the total Number of Function Evaluations (NFEs).


\vspace{1cm}